## Attention mechanism
1. [Group-Query Attention](https://arxiv.org/pdf/2305.13245)
2. [Multi-Head Latent Attention - DeepSeek-v2](https://arxiv.org/pdf/2405.04434)

## Inference Optimization
1. [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/pdf/2211.17192)

## Getting Started with Agents
1. [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)

## Multi-lingual
1. [SigLIP 2: A better multilingual vision language encoder](https://huggingface.co/blog/siglip2)

## Add the papers corresponding to Reasoning based LLMs
